#!/usr/bin/env python3
"""
Translation Script for LoreBot
Translates existing data files to supported languages
"""

import asyncio
import json
import os
import sys
from typing import Dict, List, Any, Optional
from config.settings import Settings
from utils.api_client import LLMClient
from utils.logger import setup_logger

class DataTranslator:
    """Translates astrology data files to supported languages"""
    
    def __init__(self, settings: Settings):
        self.settings = settings
        self.logger = setup_logger("data_translator")
    
    def load_support_languages(self) -> Dict[str, Any]:
        """Load supported languages configuration"""
        try:
            with open('config/support_languages.json', 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            raise FileNotFoundError("config/support_languages.json not found")
    
    def load_translation_prompt(self) -> str:
        """Load translation prompt template"""
        try:
            with open('config/translation_prompt.txt', 'r', encoding='utf-8') as f:
                return f.read().strip()
        except FileNotFoundError:
            raise FileNotFoundError("config/translation_prompt.txt not found")
    
    def load_source_file(self, filename: str) -> Dict[str, Any]:
        """Load the source data file to translate"""
        filepath = os.path.join("data", filename)
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # Validate source file before translation
            self.validate_source_file(data, filename)
            return data
            
        except FileNotFoundError:
            raise FileNotFoundError(f"Source file {filepath} not found")
    
    def validate_source_file(self, data: Dict[str, Any], filename: str):
        """Validate that all content fields in source file are valid JSON"""
        self.logger.info(f"üîç Validating source file: {filename}")
        
        if "data" not in data:
            raise ValueError(f"Source file {filename} missing 'data' field")
        
        invalid_items = []
        required_fields = ['title', 'one_liner', 'body_md']
        
        for item in data["data"]:
            if "content" not in item:
                invalid_items.append((item.get('key', 'unknown'), "Missing 'content' field"))
                continue
                
            try:
                content = json.loads(item['content'])
                
                # Check if required fields exist
                missing_fields = [field for field in required_fields if field not in content]
                if missing_fields:
                    invalid_items.append((item.get('key', 'unknown'), f"Missing fields: {missing_fields}"))
                    
            except json.JSONDecodeError as e:
                invalid_items.append((item.get('key', 'unknown'), f"Invalid JSON: {str(e)}"))
        
        if invalid_items:
            error_msg = f"‚ùå Source file validation failed for {filename}:\n"
            for key, error in invalid_items:
                error_msg += f"  - Item {key}: {error}\n"
            error_msg += "Please fix these issues before translation."
            raise ValueError(error_msg)
        
        self.logger.info(f"‚úÖ Source file validation passed: {len(data['data'])} items are valid")
    
    def validate_translated_content(self, content: Dict[str, Any], item_key: str) -> bool:
        """Validate that translated content has required fields"""
        required_fields = ['title', 'one_liner', 'body_md']
        missing_fields = [field for field in required_fields if field not in content]
        
        if missing_fields:
            self.logger.warning(f"‚ö†Ô∏è  Translated content for {item_key} missing fields: {missing_fields}")
            return False
        
        # Check if fields are not empty
        empty_fields = [field for field in required_fields if not content[field] or content[field].strip() == ""]
        if empty_fields:
            self.logger.warning(f"‚ö†Ô∏è  Translated content for {item_key} has empty fields: {empty_fields}")
            return False
        
        return Truefor LoreBot
Translates existing data files to supported languages
"""

import asyncio
import json
import os
import sys
from typing import Dict, List, Any, Optional
from config.settings import Settings
from utils.api_client import LLMClient
from utils.logger import setup_logger

class DataTranslator:
    """Translates astrology data files to supported languages"""
    
    def __init__(self, settings: Settings):
        self.settings = settings
        self.logger = setup_logger("data_translator")
    
    def load_support_languages(self) -> Dict[str, Any]:
        """Load supported languages configuration"""
        try:
            with open('config/support_languages.json', 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            raise FileNotFoundError("config/support_languages.json not found")
    
    def load_translation_prompt(self) -> str:
        """Load translation prompt template"""
        try:
            with open('config/translation_prompt.txt', 'r', encoding='utf-8') as f:
                return f.read().strip()
        except FileNotFoundError:
            raise FileNotFoundError("config/translation_prompt.txt not found")
    
    def load_source_file(self, filename: str) -> Dict[str, Any]:
        """Load the source data file to translate"""
        filepath = os.path.join("data", filename)
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except FileNotFoundError:
            raise FileNotFoundError(f"Source file {filepath} not found")
        
        # Validate all content fields before proceeding
        self.validate_source_data(data, filename)
        return data
    
    def validate_source_data(self, data: Dict[str, Any], filename: str):
        """Validate that all content fields in source data contain valid JSON with required fields"""
        self.logger.info(f"üîç Validating source data in {filename}")
        
        if "data" not in data:
            raise ValueError(f"Source file {filename} missing 'data' field")
        
        invalid_items = []
        total_items = len(data["data"])
        
        for item in data["data"]:
            item_key = item.get("key", "unknown")
            
            if "content" not in item:
                invalid_items.append((item_key, "Missing 'content' field"))
                continue
            
            try:
                content = json.loads(item["content"])
                
                # Check required fields
                required_fields = ["title", "one_liner", "body_md"]
                missing_fields = [field for field in required_fields if field not in content]
                
                if missing_fields:
                    invalid_items.append((item_key, f"Missing required fields: {missing_fields}"))
                
                # Check that fields are not empty
                empty_fields = [field for field in required_fields 
                              if field in content and not content[field].strip()]
                
                if empty_fields:
                    invalid_items.append((item_key, f"Empty required fields: {empty_fields}"))
                    
            except json.JSONDecodeError as e:
                invalid_items.append((item_key, f"Invalid JSON: {str(e)}"))
        
        if invalid_items:
            self.logger.error(f"‚ùå Validation failed for {filename}")
            self.logger.error(f"Found {len(invalid_items)} invalid items out of {total_items}:")
            for item_key, error in invalid_items:
                self.logger.error(f"  - Item {item_key}: {error}")
            
            raise ValueError(f"Source file validation failed. {len(invalid_items)} items have invalid content. "
                           f"Please fix these issues before running translation.")
        
        self.logger.info(f"‚úÖ Validation passed: All {total_items} items are valid")
    
    def get_target_filename(self, source_filename: str, target_locale: str) -> str:
        """Generate target filename with locale prefix"""
        # Remove existing locale prefix if present (e.g., eng_planets.json -> planets.json)
        if source_filename.startswith('eng_'):
            base_filename = source_filename[4:]  # Remove 'eng_' prefix
        else:
            base_filename = source_filename
        
        return f"{target_locale}_{base_filename}"
    
    def file_exists(self, filename: str) -> bool:
        """Check if target file already exists"""
        filepath = os.path.join("data", filename)
        return os.path.exists(filepath)
    
    def fill_translation_prompt(self, template: str, content: str, target_lang_name: str) -> str:
        """Fill translation prompt template with content and target language"""
        return template.replace("{content}", content).replace("{target_lang_name}", target_lang_name)
    
    async def translate_content(self, content: str, target_lang_name: str) -> str:
        """Translate content using LLM"""
        template = self.load_translation_prompt()
        prompt = self.fill_translation_prompt(template, content, target_lang_name)
        
        if self.settings.debug_mode:
            print(f"\n{'='*60}")
            print(f"TRANSLATION PROMPT –¥–ª—è {target_lang_name}:")
            print(f"{'='*60}")
            print(prompt)
            print(f"{'='*60}\n")
            return f"[DEBUG] Translated to {target_lang_name}"
        
        async with LLMClient(
            api_key=self.settings.openai_api_key,
            model=self.settings.openai_translation_model
        ) as client:
            response = await client.make_request(
                prompt=prompt,
                temperature=0.3,  # Lower temperature for translation consistency
                max_tokens=self.settings.openai_translation_max_tokens
            )
            return response.strip()
    
    async def translate_data_item(self, item: Dict[str, Any], target_lang_name: str) -> Dict[str, Any]:
        """Translate a single data item"""
        translated_item = item.copy()
        
        # Extract and translate the content field
        if 'content' in item:
            try:
                # Parse the content as JSON
                content_json = json.loads(item['content'])
                self.logger.info(f"Translating content for {item.get('key', 'unknown')} to {target_lang_name}")
                
                # Translate the entire JSON object (title, one_liner, and body_md)
                content_str = json.dumps(content_json, ensure_ascii=False, indent=2)
                translated_content_str = await self.translate_content(content_str, target_lang_name)
                
                # Parse the translated JSON and update the content
                try:
                    translated_content_json = json.loads(translated_content_str)
                    
                    # Validate translated JSON structure
                    if self.validate_translated_content(translated_content_json, item.get('key', 'unknown')):
                        translated_item['content'] = json.dumps(translated_content_json, ensure_ascii=False)
                    else:
                        # Use original content if validation fails
                        self.logger.warning(f"‚ö†Ô∏è  Using original content for {item.get('key', 'unknown')} due to validation failure")
                        translated_item['content'] = item['content']
                        
                except json.JSONDecodeError:
                    self.logger.warning(f"‚ö†Ô∏è  Failed to parse translated JSON for {item.get('key', 'unknown')}, using original content")
                    # Fallback to original content if translation parsing fails
                    translated_item['content'] = item['content']
                
                # Add delay between requests if not in debug mode
                if not self.settings.debug_mode and self.settings.delay_between_requests > 0:
                    await asyncio.sleep(self.settings.delay_between_requests)
                        
            except json.JSONDecodeError:
                self.logger.error(f"Failed to parse content JSON for {item.get('key', 'unknown')}")
                
        return translated_item
    
    def save_translated_file(self, translated_data: Dict[str, Any], target_filename: str, target_locale: str):
        """Save translated data to file"""
        output_path = os.path.join("data", target_filename)
        
        # Update metadata
        translated_data['language'] = target_locale
        translated_data['generated_at'] = translated_data.get('generated_at', '')
        
        if self.settings.debug_mode:
            self.logger.info(f"üîß DEBUG MODE: –§–∞–π–ª –ù–ï —Å–æ–∑–¥–∞–Ω - {output_path}")
            return
        
        # Ensure output directory exists
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(translated_data, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"‚úÖ Translated file saved: {output_path}")
    
    async def translate_file(self, source_filename: str):
        """Translate a source file to all supported languages"""
        self.logger.info(f"Starting translation process for: {source_filename}")
        
        # Load configurations
        support_languages = self.load_support_languages()
        source_data = self.load_source_file(source_filename)
        
        if self.settings.debug_mode:
            self.logger.info("üîß DEBUG MODE –≤–∫–ª—é—á–µ–Ω - –ø–µ—Ä–µ–≤–æ–¥—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç—Å—è –≤ –∫–æ–Ω—Å–æ–ª—å, —Ñ–∞–π–ª—ã –Ω–µ —Å–æ–∑–¥–∞—é—Ç—Å—è")
        else:
            self.logger.info("üåç –ù–∞—á–∏–Ω–∞–µ–º –ø–µ—Ä–µ–≤–æ–¥ –Ω–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —è–∑—ã–∫–∏")
        
        # Process each supported language
        for locale, lang_config in support_languages.items():
            target_filename = self.get_target_filename(source_filename, locale)
            
            # Check if target file already exists
            if not self.settings.debug_mode and self.file_exists(target_filename):
                self.logger.info(f"‚è≠Ô∏è  File {target_filename} already exists, skipping")
                continue
            
            self.logger.info(f"üîÑ Translating to {lang_config['name']} ({locale})")
            
            # Create translated data structure
            translated_data = {
                "generated_at": source_data.get("generated_at", ""),
                "language": locale,
                "total_items": source_data.get("total_items", 0),
                "data": []
            }
            
            # Translate each data item
            for item in source_data.get("data", []):
                translated_item = await self.translate_data_item(item, lang_config['name'])
                translated_data["data"].append(translated_item)
            
            # Save translated file
            self.save_translated_file(translated_data, target_filename, locale)
        
        self.logger.info(f"‚úÖ Translation completed for: {source_filename}")

async def main():
    """Main function"""
    if len(sys.argv) != 2:
        print("Usage: python3 translator.py <source_filename>")
        print("Example: python3 translator.py eng_planets_luminaries.json")
        sys.exit(1)
    
    source_filename = sys.argv[1]
    
    # Initialize settings and translator
    settings = Settings()
    translator = DataTranslator(settings)
    
    try:
        await translator.translate_file(source_filename)
        print(f"\nüéâ Translation process completed for {source_filename}!")
    except Exception as e:
        print(f"‚ùå Error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
